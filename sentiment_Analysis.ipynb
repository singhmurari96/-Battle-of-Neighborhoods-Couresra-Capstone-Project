{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0gyoCLse0wXk09Yu/Mwlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhmurari96/-Battle-of-Neighborhoods-Couresra-Capstone-Project/blob/main/sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8qK9pZAAhZa",
        "outputId": "d8bad0fc-8957-412c-e513-b044ee72970b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/433.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/433.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.11.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "!pip install emoji\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoJnXy9NAyM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "g_k9FQPTVi2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def read_csv(file_name):\n",
        "    # This function assumes that the first column contains the text and the last column contains the label\n",
        "    data = pd.read_csv(file_name)\n",
        "    X = data.iloc[:, 0].values  # Text data: only the first column\n",
        "    Y = data.iloc[:, -1].values   # Labels: the last column\n",
        "    return X, Y\n",
        "\n",
        "# Now you can read your split data using the custom function\n",
        "X_train, Y_train = read_csv('/content/train_data_with_column_name.csv')\n",
        "X_test, Y_test = read_csv('/content/tess_data.csv')\n",
        "\n",
        "# Verify the shape of the training and test sets\n",
        "print(\"Training set:\", X_train.shape, Y_train.shape)\n",
        "print(\"Test set:\", X_test.shape, Y_test.shape)\n",
        "\n",
        "# Find the maximum sentence length\n",
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())\n",
        "\n",
        "print(maxLen)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdUjtH_zhfzp",
        "outputId": "6ba2ea39-369a-417e-cb62-b02da1f9cae5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (128,) (128,)\n",
            "Test set: (56,) (56,)\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx],Y_train[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpMfDGeyt2tP",
        "outputId": "a507f32e-78da-4449-a82a-608b0708692f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French macaroon is so tasty 4\n",
            "work is horrible 3\n",
            "I am upset 3\n",
            "throw the ball 1\n",
            "Good joke 2\n",
            "what is your favorite baseball game 1\n",
            "I cooked meat 4\n",
            "stop messing around 3\n",
            "I want chinese food 4\n",
            "Let us go play baseball 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-P8iRrI59S2",
        "outputId": "8060ac01-358f-4a84-9e19-182ce2ba32f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/train_data_with_column_name.csv'  # Replace with the path to your dataset\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Display the first few entries in the dataset\n",
        "print(data.head())\n",
        "\n",
        "# If you want to see more specific rows or a random sample\n",
        "print(data.sample(5))  # Display a random sample of 5 entries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma5k6rBwi_Gw",
        "outputId": "1db1ee34-cdec-447a-fe0d-5802c615fbf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Text  Label\n",
            "0  French macaroon is so tasty      4\n",
            "1             work is horrible      3\n",
            "2                   I am upset      3\n",
            "3               throw the ball      1\n",
            "4                    Good joke      2\n",
            "                                Text  Label\n",
            "103                she is attractive      0\n",
            "61   she takes forever to get ready       3\n",
            "86      Sounds like a fun plan ha ha      2\n",
            "118              That catcher sucks       1\n",
            "36                  Great so awesome      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXBefcOd_Kw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h86EyeJlARbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxg351Y7DsBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data='/content/tess_data.csv'\n",
        "test_data=pd.read_csv(data)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "cAecghZqD4Oi",
        "outputId": "a5ae95a4-173a-456c-8f8c-54e25d9cc8d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Text  Label\n",
              "0              I want to eat      4\n",
              "1          he did not answer      3\n",
              "2   he got a very nice raise      2\n",
              "3  she got me a nice present      2\n",
              "4   ha ha ha it was so funny      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e4b6873-310d-4536-80bf-4a7570c42f56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I want to eat</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he did not answer</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he got a very nice raise</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she got me a nice present</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ha ha ha it was so funny</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e4b6873-310d-4536-80bf-4a7570c42f56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e4b6873-310d-4536-80bf-4a7570c42f56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e4b6873-310d-4536-80bf-4a7570c42f56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06c65150-53f4-42e8-bc98-16a13d94042e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06c65150-53f4-42e8-bc98-16a13d94042e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06c65150-53f4-42e8-bc98-16a13d94042e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 56,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55,\n        \"samples\": [\n          \"My life is so boring\",\n          \"he is a good friend\",\n          \"she said yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())"
      ],
      "metadata": {
        "id": "IzF14wZHEV_b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(maxLen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBX3XMPyGI9L",
        "outputId": "16b30c74-5450-492e-8de2-2926ebdddd43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tC1r4RwXGNGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2y7XG9U2IBqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the mapping from label to emoji sign\n",
        "emoji_map = {\n",
        "    0: \"❤️\",\n",
        "    1: \"⚾\",\n",
        "    2: \"😄\",\n",
        "    3: \"😞\",\n",
        "    4: \"🍴\"\n",
        "}\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/train_data_with_column_name.csv')  # Replace with the actual path\n",
        "\n",
        "# Check the column names to ensure the 'Label' column exists\n",
        "print(\"Column names:\", data.columns)\n",
        "\n",
        "# If 'Label' column exists, then map the emojis\n",
        "if 'Label' in data.columns:\n",
        "    data['Emoji'] = data['Label'].map(emoji_map)\n",
        "else:\n",
        "    print(\"The DataFrame does not contain a 'Label' column. Please check the column names.\")\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLW2GjXDKHPi",
        "outputId": "66316214-ab2e-46be-e91a-2d50ab0de7e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names: Index(['Text', 'Label'], dtype='object')\n",
            "                          Text  Label Emoji\n",
            "0  French macaroon is so tasty      4     🍴\n",
            "1             work is horrible      3     😞\n",
            "2                   I am upset      3     😞\n",
            "3               throw the ball      1     ⚾\n",
            "4                    Good joke      2     😄\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "164m2qWzKX_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the emoji mapping\n",
        "emoji_map = {\n",
        "    0: \"❤️\",  # heart\n",
        "    1: \"⚾\",  # baseball\n",
        "    2: \"😄\",  # smile\n",
        "    3: \"😞\",  # disappointed\n",
        "    4: \"🍴\"   # fork and knife\n",
        "}\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/train_data_with_column_name.csv')\n",
        "\n",
        "# Add the emoji column based on the 'Label' column\n",
        "data['Emoji'] = data['Label'].map(emoji_map)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file, if needed\n",
        "data.to_csv('train_data.csv', index=False)  # Replace with your desired path\n",
        "\n",
        "# Display the DataFrame with the emoji column\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16jfCH08LIwE",
        "outputId": "323423a6-1dce-470e-8900-4bf3684a2b35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Text  Label Emoji\n",
            "0  French macaroon is so tasty      4     🍴\n",
            "1             work is horrible      3     😞\n",
            "2                   I am upset      3     😞\n",
            "3               throw the ball      1     ⚾\n",
            "4                    Good joke      2     😄\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the emoji mapping\n",
        "emoji_map = {\n",
        "    0: \"❤️\",  # heart\n",
        "    1: \"⚾\",  # baseball\n",
        "    2: \"😄\",  # smile\n",
        "    3: \"😞\",  # disappointed\n",
        "    4: \"🍴\"   # fork and knife\n",
        "}\n",
        "\n",
        "def read_csv(file_name):\n",
        "    # This function assumes that the first column contains the text and the last column contains the label\n",
        "    data = pd.read_csv(file_name)\n",
        "    X = data.iloc[:, 0].values  # Text data: only the first column\n",
        "    Y = data.iloc[:, -1].values   # Labels: the last column\n",
        "    return X, Y\n",
        "\n",
        "# Path to the datasets\n",
        "train_file_path = '/content/train_data_with_column_name.csv'\n",
        "test_file_path = '/content/tess_data.csv'\n",
        "\n",
        "# Now you can read your split data using the custom function\n",
        "X_train, Y_train = read_csv(train_file_path)\n",
        "X_test, Y_test = read_csv(test_file_path)\n",
        "\n",
        "# Verify the shape of the training and test sets\n",
        "print(\"Training set:\", X_train.shape, Y_train.shape)\n",
        "print(\"Test set:\", X_test.shape, Y_test.shape)\n",
        "\n",
        "# Find the maximum sentence length\n",
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())\n",
        "\n",
        "print(maxLen)\n",
        "\n",
        "# Print the first 10 sentences and their labels with emojis\n",
        "for idx in range(10):\n",
        "    print(X_train[idx], emoji_map[Y_train[idx]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27WJC0p4L6Px",
        "outputId": "9816ca3f-8b2a-4e63-f30d-ac5b68bfe3ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (128,) (128,)\n",
            "Test set: (56,) (56,)\n",
            "10\n",
            "French macaroon is so tasty 🍴\n",
            "work is horrible 😞\n",
            "I am upset 😞\n",
            "throw the ball ⚾\n",
            "Good joke 😄\n",
            "what is your favorite baseball game ⚾\n",
            "I cooked meat 🍴\n",
            "stop messing around 😞\n",
            "I want chinese food 🍴\n",
            "Let us go play baseball ⚾\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(20):\n",
        "    print(X_train[idx], emoji_map[Y_train[idx]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap74HsA3Ok1p",
        "outputId": "90a30b25-7d20-496e-edb6-2d725194034a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French macaroon is so tasty 🍴\n",
            "work is horrible 😞\n",
            "I am upset 😞\n",
            "throw the ball ⚾\n",
            "Good joke 😄\n",
            "what is your favorite baseball game ⚾\n",
            "I cooked meat 🍴\n",
            "stop messing around 😞\n",
            "I want chinese food 🍴\n",
            "Let us go play baseball ⚾\n",
            "you are failing this exercise 😞\n",
            "yesterday we lost again 😞\n",
            "Good job 😄\n",
            "ha ha ha it was so funny 😄\n",
            "I will have a cheese cake 🍴\n",
            "Why are you feeling bad 😞\n",
            "I want to joke 😄\n",
            "I never said yes for this 😞\n",
            "the party is cancelled 😞\n",
            "where is the ball ⚾\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np.array(Y_train)\n",
        "Y_test = np.array(Y_test)\n",
        "print(Y_train)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMSmLHj_O7bx",
        "outputId": "39da0408-38d5-46b7-eb11-492945973a0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 3 3 1 2 1 4 3 4 1 3 3 2 2 4 3 2 3 3 1 3 2 2 2 0 1 0 4 2 0 2 0 0 3 4 0 2\n",
            " 1 3 1 0 4 0 3 0 4 2 3 4 2 2 3 0 2 2 3 2 3 2 2 3 3 0 2 3 0 2 0 0 2 3 2 4 1\n",
            " 3 3 0 0 3 2 0 3 0 2 2 4 2 2 0 0 2 3 0 4 2 1 2 3 3 2 3 0 3 0 2 0 2 3 4 3 1\n",
            " 3 4 3 2 3 3 3 1 4 4 2 2 1 1 2 3 2]\n",
            "(128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.array(Y, dtype=int)  # Ensure the labels are of type int for use as indices\n",
        "    Y_one_hot = np.eye(C)[Y.reshape(-1)]  # Create one-hot encoding\n",
        "    return Y_one_hot\n",
        "\n",
        "# Example usage:\n",
        "# Assuming Y_train and Y_test are numpy arrays with integer labels\n",
        "C = 5  # Number of classes\n",
        "Y_train = np.array(Y_train)  # Example Y_train\n",
        "Y_test = np.array(Y_test)   # Example Y_test\n",
        "\n",
        "Y_oh_train = convert_to_one_hot(Y_train, C)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C)\n",
        "print(Y_oh_test.shape)\n",
        "print(Y_oh_train.shape)\n",
        "print(\"One-hot Y_train:\\n\", Y_oh_train)\n",
        "print('')\n",
        "print(\"One-hot Y_test:\\n\", Y_oh_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfK5D5lrSsiO",
        "outputId": "e07d8049-9107-4589-bbd1-d959acefa0bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56, 5)\n",
            "(128, 5)\n",
            "One-hot Y_train:\n",
            " [[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n",
            "\n",
            "One-hot Y_test:\n",
            " [[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_emoji(label):\n",
        "    # emoji_map as defined\n",
        "    emoji_map = {\n",
        "        0: \"❤️\",  # heart\n",
        "        1: \"⚾\",  # baseball\n",
        "        2: \"😄\",  # smile\n",
        "        3: \"😞\",  # disappointed\n",
        "        4: \"🍴\"   # fork and knife\n",
        "    }\n",
        "    return emoji_map.get(label, \"Label does not exist\")  # Return the emoji or a default message\n"
      ],
      "metadata": {
        "id": "qkSdSFxwXSZG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 52\n",
        "print(f\"Sentence '{X_train[idx]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
        "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sri0nSWLYdhT",
        "outputId": "eecd4cc9-5658-44d2-a4c3-2c32e0e2e08e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 'I love taking breaks' has label index 0, which is emoji ❤️\n",
            "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings_and_get_statistics(file_path):\n",
        "    vocab_size = 0\n",
        "    embedding_dim = None\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            vocab_size += 1\n",
        "            if embedding_dim is None:\n",
        "                parts = line.strip().split()\n",
        "                embedding_dim = len(parts) - 1  # Subtract 1 for the word itself\n",
        "    return vocab_size, embedding_dim\n",
        "\n",
        "# Path to the GloVe file\n",
        "glove_file_path = '/content/glove.6B.50d.txt'  # Update this path to your file's location\n",
        "\n",
        "# Load the GloVe embeddings and get statistics\n",
        "vocab_size, embedding_dim = load_glove_embeddings_and_get_statistics(glove_file_path)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Embedding dimension: {embedding_dim}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q-WW218fUih",
        "outputId": "b4bd1578-dbbd-4dcc-83e3-21a4ad3b4fc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 400000\n",
            "Embedding dimension: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r', encoding='utf-8') as file:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        word_to_index = {}\n",
        "        index_to_word = {}\n",
        "\n",
        "        for index, line in enumerate(file):\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "            word_to_index[curr_word] = index\n",
        "            index_to_word[index] = curr_word\n",
        "\n",
        "    return word_to_index, index_to_word, word_to_vec_map\n",
        "\n",
        "# Example usage\n",
        "# glove_file = 'data/glove.6B.50d.txt'  # Update the path according to your file location\n",
        "# word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(glove_file)\n"
      ],
      "metadata": {
        "id": "oDYfSi4UkISv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "iagNeJHMlAaU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"cucumber\"\n",
        "idx =  289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj7A4QO5lRXO",
        "outputId": "d997bf4e-5b7f-4099-8483-a7e5cf64fafa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the index of cucumber in the vocabulary is 29794\n",
            "the 289846th word in the vocabulary is valeriana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_vec_map['love'])"
      ],
      "metadata": {
        "id": "NP7-r3Enlbsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ac93c2-35ff-414c-a5d7-570b9c9fed29"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.13886    1.1401    -0.85212   -0.29212    0.75534    0.82762\n",
            " -0.3181     0.0072204 -0.34762    1.0731    -0.24665    0.97765\n",
            " -0.55835   -0.090318   0.83182   -0.33317    0.22648    0.30913\n",
            "  0.026929  -0.086739  -0.14703    1.3543     0.53695    0.43735\n",
            "  1.2749    -1.4382    -1.2815    -0.15196    1.0506    -0.93644\n",
            "  2.7561     0.58967   -0.29473    0.27574   -0.32928   -0.201\n",
            " -0.28547   -0.45987   -0.14603   -0.69372    0.070761  -0.19326\n",
            " -0.1855    -0.16095    0.24268    0.20784    0.030924  -1.3711\n",
            " -0.28606    0.2898   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_vec_map['love'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFGpen9RRIDt",
        "outputId": "8bf8db80-7404-4753-a689-b3f0b950feec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_vec_map['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e17ydq6VRROw",
        "outputId": "705f2b34-8e05-4c98-a89d-785cd4902c96"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUchedUxRf4o"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xQ-g77KRrFE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "any_word = list(word_to_vec_map.keys())[0]\n"
      ],
      "metadata": {
        "id": "sceJkt-gRtiq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_vec_map[any_word].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLC8TI33ULjT",
        "outputId": "d8809d52-307a-4e98-96bb-2724239523ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_avg(sentence,word_to_vec_map):\n",
        "  any_word=list(word_to_vec_map.keys())[0]\n",
        "  words=sentence.lower().split()\n",
        "  avg=np.zeros(word_to_vec_map[any_word].shape)\n",
        "  count=0\n",
        "  for w in words:\n",
        "    if w in word_to_vec_map:\n",
        "      avg+=word_to_vec_map[w]\n",
        "      count=count+1\n",
        "  if count>0:\n",
        "    avg=avg/count\n",
        "  return avg\n",
        "\n"
      ],
      "metadata": {
        "id": "UVoH9WNzUOh3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# BEGIN UNIT TEST\n",
        "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
        "print(\"avg = \\n\", avg)\n",
        "\n",
        "def sentence_to_avg_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    avg = target(\"a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert tuple(avg.shape) == tuple(word_to_vec_map['a'].shape),  \"Check the shape of your avg array\"\n",
        "    assert np.allclose(avg, [1.25, 2.5]),  \"Check that you are finding the 4 words\"\n",
        "    avg = target(\"love a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [1.25, 2.5]), \"Divide by count, not len(words)\"\n",
        "    avg = target(\"love\", word_to_vec_map)\n",
        "    assert np.array_equal(avg, [0, 0]), \"Average of no words must give an array of zeros\"\n",
        "    avg = target(\"c_se foo a a_nw c_w a_s deeplearning c_nw\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0.1666667, 2.0]), \"Debug the last example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentence_to_avg_test(sentence_to_avg)\n",
        "\n",
        "# END UNIT TEST"
      ],
      "metadata": {
        "id": "xkQZtQTUUUDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10e89cd-93b4-46a3-cca7-ef89840f1f75"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg = \n",
            " [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
            " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
            "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
            "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
            "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
            "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
            " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
            " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
            "  0.1445417   0.09808667]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, Y, W, b, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Given X (sentences), W (weights), b (bias), and word_to_vec_map, predict the labels.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, array of sentences\n",
        "    Y -- true labels, not used in prediction but included to match the function call\n",
        "    W -- weight matrix of the softmax layer\n",
        "    b -- bias of the softmax layer\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation\n",
        "\n",
        "    Returns:\n",
        "    preds -- vector of predictions, an array of integers\n",
        "    \"\"\"\n",
        "    m = X.shape[0]  # number of examples\n",
        "    preds = np.zeros((m, 1))  # Initialize predictions\n",
        "\n",
        "    for i in range(m):\n",
        "        # Split sentences into words\n",
        "        words = X[i].lower().split()\n",
        "\n",
        "        # Initialize the average word vector\n",
        "        avg = np.zeros((word_to_vec_map[list(word_to_vec_map.keys())[0]].shape[0],))\n",
        "\n",
        "        # Sum the GloVe vectors\n",
        "        count = 0\n",
        "        for w in words:\n",
        "            if w in word_to_vec_map:\n",
        "                avg += word_to_vec_map[w]\n",
        "                count += 1\n",
        "        if count > 0:  # To avoid division by zero\n",
        "            avg = avg / count\n",
        "\n",
        "        # Forward propagation\n",
        "        z = np.dot(W, avg) + b\n",
        "        a = softmax(z)\n",
        "\n",
        "        # Convert probabilities to predicted class\n",
        "        preds[i] = np.argmax(a)\n",
        "\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "CEC8kAIoalFl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
        "    # Compute e^x for each element in x\n",
        "    e_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
        "    # Divide each e^x by the sum of all e^x to get the probabilities\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# Example usage:\n",
        "scores = [3.0, 1.0, 0.2]\n",
        "print(softmax(scores))\n",
        "print(softmax(scores).shape)\n",
        "print(len(scores))\n",
        "\n",
        "print(sum(softmax(scores)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYCtb-Z9bs1c",
        "outputId": "cdd46567-37d3-407f-f6b7-39d1128ab9f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8360188  0.11314284 0.05083836]\n",
            "(3,)\n",
            "3\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
        "    \"\"\"\n",
        "    Model to train word vector representations in numpy.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, numpy array of sentences as strings, of shape (m,)\n",
        "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
        "    num_iterations -- number of iterations\n",
        "\n",
        "    Returns:\n",
        "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
        "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
        "    b -- bias of the softmax layer, of shape (n_y,)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get a valid word contained in the word_to_vec_map\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "\n",
        "    # Define number of training examples\n",
        "    m = Y.shape[0]                             # number of training examples\n",
        "    n_y = len(np.unique(Y))                    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors\n",
        "\n",
        "    # Initialize parameters using Xavier initialization\n",
        "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
        "    b = np.zeros((n_y,))\n",
        "\n",
        "    # Convert Y to Y_onehot with n_y classes\n",
        "    Y_oh = convert_to_one_hot(Y, C = n_y)\n",
        "\n",
        "    # Optimization loop\n",
        "    for t in range(num_iterations): # Loop over the number of iterations\n",
        "\n",
        "        cost = 0\n",
        "        dW = 0\n",
        "        db = 0\n",
        "\n",
        "        for i in range(m):          # Loop over the training examples\n",
        "\n",
        "            ### START CODE HERE ### (≈ 4 lines of code)\n",
        "            # Average the word vectors of the words from the i'th training example\n",
        "            ### START CODE HERE ### (≈ 4 lines of code)\n",
        "            # Average the word vectors of the words from the i'th training example\n",
        "            words = X[i].lower().split()\n",
        "            avg = np.zeros((n_h,))\n",
        "            count = 0\n",
        "            for w in words:\n",
        "                if w in word_to_vec_map:\n",
        "                    avg += word_to_vec_map[w]\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                avg = avg / count\n",
        "\n",
        "            # Forward propagate the avg through the softmax layer.\n",
        "            # You can use np.dot() to perform the multiplication.\n",
        "            z = np.dot(W, avg) + b\n",
        "            a = softmax(z)\n",
        "\n",
        "            # Add the cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
        "            cost += -np.sum(Y_oh[i] * np.log(a))\n",
        "            ### END CODE HERE ###\n",
        "\n",
        "            # Compute gradients\n",
        "            dz = a - Y_oh[i]\n",
        "            dW += np.outer(dz, avg)\n",
        "            db += dz\n",
        "\n",
        "            # Update parameters with Stochastic Gradient Descent\n",
        "            W = W - learning_rate * dW\n",
        "            b = b - learning_rate * db\n",
        "\n",
        "        assert type(cost) == np.float64, \"Incorrect implementation of cost\"\n",
        "        assert cost.shape == (), \"Incorrect implementation of cost\"\n",
        "\n",
        "        if t % 100 == 0:\n",
        "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
        "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
        "    return pred, W, b"
      ],
      "metadata": {
        "id": "g3sr63GBd0U2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIT TEST\n",
        "def model_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Training set. Sentences composed of a_* words will be of class 0 and sentences composed of c_* words will be of class 1\n",
        "    X = np.asarray(['a a_s synonym_of_a a_n c_sw', 'a a_s a_n c_sw', 'a_s  a a_n', 'synonym_of_a a a_s a_n c_sw', \" a_s a_n\",\n",
        "                    \" a a_s a_n c \", \" a_n  a c c c_e\",\n",
        "                   'c c_nw c_n c c_ne', 'c_e c c_se c_s', 'c_nw c a_s c_e c_e', 'c_e a_nw c_sw', 'c_sw c c_ne c_ne'])\n",
        "\n",
        "    Y = np.asarray([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "    np.random.seed(10)\n",
        "    pred, W, b = model(X, Y, word_to_vec_map, 0.0025, 110)\n",
        "\n",
        "    assert W.shape == (2, 2), \"W must be of shape 2 x 2\"\n",
        "    assert np.allclose(pred.transpose(), Y), \"Model must give a perfect accuracy\"\n",
        "    assert np.allclose(b[0], -1 * b[1]), \"b should be symmetric in this example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "model_test(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Uj26lAfLFI",
        "outputId": "97ac718a-c42a-4357-aadf-d4e51f4ed026"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = 2.603378473480253\n",
            "Epoch: 100 --- cost = 0.4732825238878884\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AckyFrufRyq",
        "outputId": "634b91fa-7830-4f66-e75a-d0d662c92d12"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = 495.4001890322268\n",
            "Epoch: 100 --- cost = 83.45073221020563\n",
            "Epoch: 200 --- cost = 3.6468876336060796\n",
            "Epoch: 300 --- cost = 0.5584884808807373\n",
            "[[4.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [2.]\n",
            " [1.]\n",
            " [4.]\n",
            " [3.]\n",
            " [4.]\n",
            " [1.]\n",
            " [3.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [4.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [4.]\n",
            " [2.]\n",
            " [0.]\n",
            " [2.]\n",
            " [0.]\n",
            " [0.]\n",
            " [3.]\n",
            " [4.]\n",
            " [0.]\n",
            " [2.]\n",
            " [1.]\n",
            " [3.]\n",
            " [1.]\n",
            " [0.]\n",
            " [4.]\n",
            " [0.]\n",
            " [3.]\n",
            " [0.]\n",
            " [4.]\n",
            " [2.]\n",
            " [3.]\n",
            " [4.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [0.]\n",
            " [0.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]\n",
            " [4.]\n",
            " [1.]\n",
            " [3.]\n",
            " [3.]\n",
            " [0.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]\n",
            " [0.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [2.]\n",
            " [4.]\n",
            " [2.]\n",
            " [2.]\n",
            " [0.]\n",
            " [0.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [4.]\n",
            " [2.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [0.]\n",
            " [3.]\n",
            " [0.]\n",
            " [2.]\n",
            " [0.]\n",
            " [2.]\n",
            " [3.]\n",
            " [4.]\n",
            " [3.]\n",
            " [1.]\n",
            " [3.]\n",
            " [4.]\n",
            " [3.]\n",
            " [2.]\n",
            " [3.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [4.]\n",
            " [4.]\n",
            " [2.]\n",
            " [2.]\n",
            " [1.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set:\")\n",
        "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
        "print('Test set:')\n",
        "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8de9xdKiK8Q",
        "outputId": "75011938-178a-4536-fb71-ef26905bcb7d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Test set:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_predictions(X, preds):\n",
        "    \"\"\"\n",
        "    Prints the sentences and their associated predictions.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data (sentences), numpy array of shape (m,)\n",
        "    preds -- predictions, numpy array of shape (m, 1)\n",
        "    \"\"\"\n",
        "    for i in range(X.shape[0]):\n",
        "        print(f\"{X[i]} -> {label_to_emoji(int(preds[i]))}\")\n",
        "\n",
        "# Assuming label_to_emoji is already defined and uses the emoji_map\n",
        "def label_to_emoji(label):\n",
        "    emoji_map = {\n",
        "        0: \"❤️\",  # heart\n",
        "        1: \"⚾\",  # baseball\n",
        "        2: \"😄\",  # smile\n",
        "        3: \"😞\",  # disappointed\n",
        "        4: \"🍴\"   # fork and knife\n",
        "    }\n",
        "    return emoji_map.get(label, \"Label not found\")  # Return emoji or a default message\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iv566vu4iWpL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_my_sentences = np.array([\"i treasure you\", \"i love you\", \"funny lol\", \"lets play with a ball\",\n",
        "                           \"food is ready\", \"today is not good\"])\n",
        "print(f\"shape of x_my_sentences=\",{X_my_sentences.shape})\n",
        "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
        "\n",
        "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
        "print_predictions(X_my_sentences, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXvA0h9zig_U",
        "outputId": "fd3a19a8-ddf8-4144-bb4e-f7d667e57413"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_my_sentences= {(6,)}\n",
            "i treasure you -> ❤️\n",
            "i love you -> ❤️\n",
            "funny lol -> 😄\n",
            "lets play with a ball -> ⚾\n",
            "food is ready -> 🍴\n",
            "today is not good -> 😄\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b4cb12506b56>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"{X[i]} -> {label_to_emoji(int(preds[i]))}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns  # For a nicer looking confusion matrix\n",
        "\n",
        "def plot_confusion_matrix(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix using matplotlib and seaborn.\n",
        "\n",
        "    Arguments:\n",
        "    Y_true -- true labels, numpy array of shape (m, 1)\n",
        "    Y_pred -- predictions, numpy array of shape (m, 1)\n",
        "    \"\"\"\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(Y_true, Y_pred)\n",
        "\n",
        "    # Use seaborn to create a more visually appealing confusion matrix\n",
        "    sns.set(font_scale=1.4)  # for label size\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")  # annot=True to annotate cells, fmt=\"d\" to disable scientific notation\n",
        "\n",
        "    # Labels, title and ticks\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Ensure Y_test and pred_test are numpy arrays and have the shape (m, 1) or (m,)\n",
        "# You might need to use np.squeeze() if your predictions are in a different shape\n",
        "# plot_confusion_matrix(Y_test, np.squeeze(pred_test))\n"
      ],
      "metadata": {
        "id": "FMGLAVWXjViE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test.shape)\n",
        "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' +\n",
        "      label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
        "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "plot_confusion_matrix(Y_test, pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "iIJr5LA4jgU7",
        "outputId": "49d8b92f-aa80-4c58-c9d0-dfcd59577518"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56,)\n",
            "           ❤️    ⚾    😄    😞   🍴\n",
            "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
            "Actual                                 \n",
            "0            6    0    1    0    0    7\n",
            "1            0    8    0    0    0    8\n",
            "2            5    0   13    0    0   18\n",
            "3            1    0    3   12    0   16\n",
            "4            1    0    2    0    4    7\n",
            "All         13    8   19   12    4   56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " m = Y_train.shape[0]\n",
        " print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkYLNpd-j7pT",
        "outputId": "583ac646-9b4d-4a61-d0ec-80d64d4afe13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_y = len(np.unique(Y_train))\n",
        "print(n_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwX-LnZFDtN8",
        "outputId": "0bd8d315-becc-4cb6-b79e-ba7c44559826"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_h=word_to_vec_map[any_word].shape[0]\n",
        "print(n_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPLFhWmeD6j7",
        "outputId": "2ad093fe-abbe-4a7e-b904-5508102b1210"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy of predictions.\n",
        "\n",
        "    Arguments:\n",
        "    Y_true -- true labels, numpy array (or list) of shape (m, 1) or (m,)\n",
        "    Y_pred -- predictions, numpy array (or list) of shape (m, 1) or (m,)\n",
        "\n",
        "    Returns:\n",
        "    acc -- accuracy of predictions.\n",
        "    \"\"\"\n",
        "    Y_true = np.squeeze(Y_true)  # Remove single-dimensional entries from the shape\n",
        "    Y_pred = np.squeeze(Y_pred)\n",
        "    correct_predictions = np.sum(Y_true == Y_pred)\n",
        "    total_predictions = Y_true.shape[0]\n",
        "    acc = correct_predictions / total_predictions\n",
        "    return acc\n",
        "\n",
        "# Assuming X_train, Y_train, X_test, and Y_test are already defined\n",
        "print(\"Training set:\")\n",
        "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
        "train_accuracy = accuracy(Y_train, pred_train)\n",
        "print(f\"Accuracy on training set: {train_accuracy*100:.2f}%\")\n",
        "\n",
        "print('Test set:')\n",
        "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)\n",
        "test_accuracy = accuracy(Y_test, pred_test)\n",
        "print(f\"Accuracy on test set: {test_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9aknvhHEJWY",
        "outputId": "cebe73c3-9149-4d8c-d65c-d0e09fc0f862"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Accuracy on training set: 100.00%\n",
            "Test set:\n",
            "Accuracy on test set: 76.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Dropout,Input,LSTM,Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "TML2AyIad07i"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,val in enumerate([\"I\", \"like\", \"learning\"]):\n",
        "  print(idx,val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KALxafxtrJbd",
        "outputId": "ba56b672-fb7e-4def-cd3a-f5b33a05cce0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 I\n",
            "1 like\n",
            "2 learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentences_to_indices(x,word_to_index,maxLen):\n",
        "  m=x.shape[0]\n",
        "  x_indices=np.zeros((m,maxLen))\n",
        "  for i in range(m):\n",
        "    sentence_word=x[i].lower().split()\n",
        "    j=0\n",
        "    for w in sentence_word:\n",
        "      if w in word_to_index:\n",
        "        x_indices[i,j]=word_to_index[w]\n",
        "        j=j+1\n",
        "  return x_indices\n"
      ],
      "metadata": {
        "id": "w3UAjOzUuw-7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"I think, therefore I am.\"\n",
        "]\n",
        "\n",
        "# Clean sentences to remove punctuation and convert to lowercase\n",
        "sentence_clean = [re.sub(r'[^\\w\\s]', '', sentence).lower() for sentence in sentences]\n",
        "\n",
        "# Convert the list of cleaned sentences to a NumPy array\n",
        "x = np.array(sentence_clean)\n",
        "indices=sentences_to_indices(x,word_to_index,20)\n",
        "print(f\"indices\\n={indices}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asmv1IN927LR",
        "outputId": "4c4c55bf-9353-4ea4-ca54-3912eca9db69"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indices\n",
            "=[[0.0000e+00 2.5820e+03 1.0420e+03 2.1060e+03 1.1070e+04 7.4000e+01\n",
            "  0.0000e+00 1.6531e+04 2.9260e+03 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00]\n",
            " [7.0000e+00 3.9300e+03 3.0000e+00 7.0000e+00 4.1190e+03 6.7900e+02\n",
            "  2.2760e+03 1.7000e+01 7.0000e+00 5.9200e+02 1.0650e+03 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00]\n",
            " [4.0000e+00 3.0000e+01 4.6000e+01 3.6000e+01 4.0000e+00 3.0000e+01\n",
            "  1.2000e+01 1.4000e+01 0.0000e+00 9.9500e+02 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00]\n",
            " [6.4000e+01 1.2000e+01 9.4594e+04 1.4000e+01 3.6000e+01 7.6400e+02\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00]\n",
            " [4.1000e+01 2.6900e+02 2.3170e+03 4.1000e+01 9.1300e+02 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
            "  0.0000e+00 0.0000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "def sentences_to_indices_test(target):\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate([\"i\", \"like\", \"learning\", \"deep\", \"machine\", \"love\", \"smile\", '´0.=']):\n",
        "        word_to_index[val] = idx + 1;\n",
        "    print(word_to_index)\n",
        "    max_len = 4\n",
        "    sentences = np.array([\"I like deep learning\", \"deep ´0.= love machine\", \"machine learning smile\", \"$\"]);\n",
        "    indexes = target(sentences, word_to_index, max_len)\n",
        "    print(indexes)\n",
        "\n",
        "    assert type(indexes) == np.ndarray, \"Wrong type. Use np arrays in the function\"\n",
        "    assert indexes.shape == (sentences.shape[0], max_len), \"Wrong shape of ouput matrix\"\n",
        "    assert np.allclose(indexes, [[1, 2, 4, 3],\n",
        "                                 [4, 8, 6, 5],\n",
        "                                 [5, 3, 7, 0],\n",
        "                                 [0, 0, 0, 0]]), \"Wrong values. Debug with the given examples\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentences_to_indices_test(sentences_to_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vYv0jFU4iMT",
        "outputId": "aa27bb32-35f8-4205-9f6e-5b27961a0835"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'like': 2, 'learning': 3, 'deep': 4, 'machine': 5, 'love': 6, 'smile': 7, '´0.=': 8}\n",
            "[[1. 2. 4. 3.]\n",
            " [4. 8. 6. 5.]\n",
            " [5. 3. 7. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1, word_to_index, 5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\\n\", X1_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AafxuRHw9oBw",
        "outputId": "a4d010de-3c01-4651-dc6b-29718ba2e744"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "X1_indices =\n",
            " [[5.4660e+03 7.3048e+04 0.0000e+00 0.0000e+00 0.0000e+00]\n",
            " [8.2350e+03 2.8200e+02 1.4440e+03 0.0000e+00 0.0000e+00]\n",
            " [5.6500e+02 1.4000e+01 1.1880e+03 1.0000e+01 8.1000e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example to understand the funtionality of the items() funtion\n",
        "student_scores = {1: 85, 2: 92, 3: 78, 4: 90}\n",
        "for student_id, score in student_scores.items():\n",
        "    print(f\"Student ID: {student_id}, Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2crpqSfbC4Wr",
        "outputId": "a6a7ae54-d513-4d13-a31a-8633158db9d3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student ID: 1, Score: 85\n",
            "Student ID: 2, Score: 92\n",
            "Student ID: 3, Score: 78\n",
            "Student ID: 4, Score: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize the embedding matrix with zeros. Shape: vocab_size (6) x embedding_dim (3)\n",
        "embedding_matrix = np.zeros((6, 3))\n",
        "\n",
        "# Fill in the embedding matrix with our predefined vectors\n",
        "embedding_matrix[1] = [0.21, -0.96, 0.75]\n",
        "embedding_matrix[2] = [0.25, -0.92, 0.78]\n",
        "embedding_matrix[3] = [-0.65, 0.80, -0.23]\n",
        "embedding_matrix[4] = [-0.68, 0.75, -0.20]\n",
        "embedding_matrix[5] = [0.99, 0.01, 0.32]\n",
        "\n",
        "print(\"Embedding Matrix:\\n\", embedding_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijVYb-9yiD2l",
        "outputId": "d5ad53c0-d7d8-482d-ba48-190ea99b1acd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix:\n",
            " [[ 0.    0.    0.  ]\n",
            " [ 0.21 -0.96  0.75]\n",
            " [ 0.25 -0.92  0.78]\n",
            " [-0.65  0.8  -0.23]\n",
            " [-0.68  0.75 -0.2 ]\n",
            " [ 0.99  0.01  0.32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map,word_to_index):\n",
        "  vocab_size=len(word_to_index)+1\n",
        "  any_word=list(word_to_vec_map.keys())[0]\n",
        "  emb_dim=word_to_vec_map[any_word].shape[0]\n",
        "  emb_matrix=np.zeros((vocab_size,emb_dim))\n",
        "  for word,idx in word_to_index.items():\n",
        "    emb_matrix[idx,:]=word_to_vec_map[word]\n",
        "  embedding_layer=Embedding(input_dim=vocab_size,output_dim=emb_dim,trainable=False)\n",
        "  embedding_layer.build((None,))\n",
        "  embedding_layer.set_weights([emb_matrix])\n",
        "  return embedding_layer"
      ],
      "metadata": {
        "id": "Fge_Vw12jFoY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "def pretrained_embedding_layer_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    np.random.seed(1)\n",
        "    embedding_layer = target(word_to_vec_map, word_to_index)\n",
        "\n",
        "    assert type(embedding_layer) == Embedding, \"Wrong type\"\n",
        "    assert embedding_layer.input_dim == len(list(word_to_vec_map.keys())) + 1, \"Wrong input shape\"\n",
        "    assert embedding_layer.output_dim == len(word_to_vec_map['a']), \"Wrong output shape\"\n",
        "    assert np.allclose(embedding_layer.get_weights(),\n",
        "                       [[[ 3, 3], [ 3, 3], [ 2, 4], [ 3, 2], [ 3, 4],\n",
        "                       [-2, 1], [-2, 2], [-1, 2], [-1, 1], [-1, 0],\n",
        "                       [-2, 0], [-3, 0], [-3, 1], [-3, 2], [ 0, 0]]]), \"Wrong vaulues\"\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "\n",
        "pretrained_embedding_layer_test(pretrained_embedding_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfABhdHUGvsI",
        "outputId": "db7063c1-155e-4b34-80b6-fcd06c63da57"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
        "print(\"Input_dim\", embedding_layer.input_dim)\n",
        "print(\"Output_dim\",embedding_layer.output_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoOgZTvkHI0Z",
        "outputId": "fa5bcd22-5c14-4815-d4c8-6e5d5a91603d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights[0][1][1] = 0.23682\n",
            "Input_dim 400001\n",
            "Output_dim 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "for key in word_to_vec_map.keys():\n",
        "  word_to_vec_map[key]=np.array(word_to_vec_map[key])\n",
        "print(word_to_vec_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf7o7KCjHc6l",
        "outputId": "a5732644-e22e-48b7-d1af-c30be466f0ed"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': array([3, 3]), 'synonym_of_a': array([3, 3]), 'a_nw': array([2, 4]), 'a_s': array([3, 2]), 'a_n': array([3, 4]), 'c': array([-2,  1]), 'c_n': array([-2,  2]), 'c_ne': array([-1,  2]), 'c_e': array([-1,  1]), 'c_se': array([-1,  0]), 'c_s': array([-2,  0]), 'c_sw': array([-3,  0]), 'c_w': array([-3,  1]), 'c_nw': array([-3,  2])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "any_word=list(word_to_vec_map.keys())[0]\n",
        "dim=word_to_vec_map[any_word].shape[0]\n",
        "print(f\"dim={dim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XA29RLhKnjQ",
        "outputId": "0440abfd-09a1-4258-98aa-1677adf24c56"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim=2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index={}\n",
        "for idx,val in enumerate(list(word_to_vec_map.keys())):\n",
        "  word_to_index[val]=idx;\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIWIVw6gLRlh",
        "outputId": "45857169-c4f3-49b4-c260-3ab7c77f850e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'synonym_of_a': 1, 'a_nw': 2, 'a_s': 3, 'a_n': 4, 'c': 5, 'c_n': 6, 'c_ne': 7, 'c_e': 8, 'c_se': 9, 'c_s': 10, 'c_sw': 11, 'c_w': 12, 'c_nw': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())\n",
        "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Function creating the Emojify-v2 model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, usually (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Define sentence_indices as the input of the graph.\n",
        "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
        "    sentence_indices = Input(input_shape, dtype='int32')\n",
        "\n",
        "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "\n",
        "    # Propagate sentence_indices through your embedding layer\n",
        "    # (See additional hints in the instructions).\n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "\n",
        "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
        "    # The returned output should be a batch of sequences.\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(0.5)(X)\n",
        "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
        "    # The returned output should be a single hidden state, not a batch of sequences.\n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(0.5)(X)\n",
        "    # Propagate X through a Dense layer with 5 units\n",
        "    X = Dense(5)(X)\n",
        "    # Add a softmax activation\n",
        "    X = Activation('softmax')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = Model(sentence_indices, X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    print(type(model))  # Add this line before the return statement in Emojify_V2\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HKvfPZa3NO8a"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))  # This should output <class 'tensorflow.python.keras.engine.functional.Functional'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p13PUicFODv",
        "outputId": "3e4ee6f8-cefc-4408-b67f-e314b34fc885"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'function'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Activation, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    # Mock implementation for illustration; replace with your actual implementation.\n",
        "    vocab_len = len(word_to_index) + 1  # adding 1 to fit Keras embedding (Keras requires indexing from 1)\n",
        "    emb_dim = word_to_vec_map['c'].shape[0]  # example to get dimensionality of embeddings\n",
        "\n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "\n",
        "    return embedding_layer\n",
        "\n",
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "    # Ensure the function creates and returns a Keras Model instance.\n",
        "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
        "\n",
        "    # Create the embedding layer\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = LSTM(128)(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(5)(X)\n",
        "    X = Activation('softmax')(X)\n",
        "\n",
        "    model = Model(inputs=sentence_indices, outputs=X)  # This creates a Functional model instance\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_qNb4xn2FsyQ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KA5gj3sFwDX",
        "outputId": "c425cad2-4e3d-4432-adfa-d2eb5fcad6da"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.src.engine.functional.Functional'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(model):\n",
        "    \"\"\"\n",
        "    Generate a simplified summary of a Keras model.\n",
        "\n",
        "    Arguments:\n",
        "    model -- A Keras model instance.\n",
        "\n",
        "    Returns:\n",
        "    model_summary -- A list of lists containing details about each layer\n",
        "                     in the model. Each inner list\n",
        "                     contains the layer type,\n",
        "                     output shape, and number of parameters.\n",
        "    \"\"\"\n",
        "    model_summary = []\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layer_type = layer.__class__.__name__\n",
        "        output_shape = layer.output_shape\n",
        "        params = layer.count_params()\n",
        "\n",
        "        # Some layers might have multiple output shapes (e.g., in multi-output models).\n",
        "        # For simplicity, we'll only consider the first output shape if it's a list.\n",
        "        if isinstance(output_shape, list):\n",
        "            output_shape = output_shape[0]\n",
        "\n",
        "        layer_summary = [layer_type, output_shape, params]\n",
        "        model_summary.append(layer_summary)\n",
        "\n",
        "    return model_summary"
      ],
      "metadata": {
        "id": "wGSETmUWTUuM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparator(actual, expected):\n",
        "    \"\"\"\n",
        "    Compares the summary of the actual model against an expected model summary.\n",
        "\n",
        "    Arguments:\n",
        "    actual -- the actual model summary as a list of layer details\n",
        "    expected -- the expected model summary as a list of layer details\n",
        "    \"\"\"\n",
        "    assert len(actual) == len(expected), \"Number of layers does not match expected model.\"\n",
        "\n",
        "    for actual_layer, expected_layer in zip(actual, expected):\n",
        "        # Compare layer types\n",
        "        assert actual_layer[0] == expected_layer[0], f\"Expected layer type {expected_layer[0]}, but got {actual_layer[0]}\"\n",
        "        # Compare output shapes, if provided\n",
        "        if len(actual_layer) > 1 and actual_layer[1] is not None:\n",
        "            assert actual_layer[1] == expected_layer[1], f\"Expected shape {expected_layer[1]}, but got {actual_layer[1]}\"\n",
        "        # Compare number of parameters, if provided\n",
        "        if len(actual_layer) > 2 and actual_layer[2] is not None:\n",
        "            assert actual_layer[2] == expected_layer[2], f\"Expected params {expected_layer[2]}, but got {actual_layer[2]}\"\n",
        "\n",
        "    print(\"\\033[92mModel structure matches expected.\")\n"
      ],
      "metadata": {
        "id": "fPq5sAdce_vg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hF8LK4pPnOTw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.engine.functional import Functional\n",
        "\n",
        "def Emojify_V2_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    maxLen = 4\n",
        "    model = target((maxLen,), word_to_vec_map, word_to_index)\n",
        "\n",
        "    assert type(model) == Functional, \"Make sure you have correctly created Model instance which converts \\\"sentence_indices\\\" into \\\"X\\\"\"\n",
        "\n",
        "    expectedModel = [\n",
        "    ['InputLayer', [(None, 4)], 0],  # Defines an input layer expecting sequences of length 4.\n",
        "    ['Embedding', (None, 4, 2), 30],  # An embedding layer mapping each timestep in the input sequence to a 2D vector; total 30 parameters.\n",
        "    ['LSTM', (None, 4, 128), 67072, (None, 4, 2), 'tanh', True],  # First LSTM layer as explained above.\n",
        "    ['Dropout', (None, 4, 128), 0, 0.5],  # A dropout layer applied to the output of the LSTM layer, with a dropout rate of 0.5; it does not add parameters.\n",
        "    ['LSTM', (None, 128), 131584, (None, 4, 128), 'tanh', False],  # Second LSTM layer, returning only the last output of the sequence.\n",
        "    ['Dropout', (None, 128), 0, 0.5],  # Another dropout layer, now applied to the final output of the previous LSTM layer.\n",
        "    ['Dense', (None, 5), 645, 'linear'],  # A Dense layer with 5 units (for classification into 5 classes), using a linear activation function.\n",
        "    ['Activation', (None, 5), 0]  # An activation layer applying a non-linear activation to the output of the Dense layer; typically used for the final model output.\n",
        "]\n",
        "\n",
        "    comparator(summary(model), expectedModel)\n",
        "\n",
        "\n",
        "Emojify_V2_test(Emojify_V2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "BxFTiRnMA8vH",
        "outputId": "9ffbcf1c-2b79-4cbe-ff18-c8d97f03209f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.src.engine.functional.Functional'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Make sure you have correctly created Model instance which converts \"sentence_indices\" into \"X\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e18eea30d35f>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mEmojify_V2_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmojify_V2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-e18eea30d35f>\u001b[0m in \u001b[0;36mEmojify_V2_test\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxLen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_vec_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Make sure you have correctly created Model instance which converts \\\"sentence_indices\\\" into \\\"X\\\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     expectedModel = [\n",
            "\u001b[0;31mAssertionError\u001b[0m: Make sure you have correctly created Model instance which converts \"sentence_indices\" into \"X\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KixGiSujBC7-",
        "outputId": "5e80855e-3da0-41f3-f53a-b519b8ea8bb2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.src.engine.functional.Functional'>\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 10, 50)            20000050  \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 10, 128)           91648     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20223927 (77.15 MB)\n",
            "Trainable params: 223877 (874.52 KB)\n",
            "Non-trainable params: 20000050 (76.29 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "L0Yullm6GlGY"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
      ],
      "metadata": {
        "id": "fFL7Msp1rOYG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDeBKuK1rTCf",
        "outputId": "f0a3d1ad-467a-4e1d-e37d-3a3bad716170"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 30ms/step - loss: 1.5985 - accuracy: 0.2422\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.5035 - accuracy: 0.2891\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.5248 - accuracy: 0.3516\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.4737 - accuracy: 0.3672\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.4032 - accuracy: 0.4375\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.3349 - accuracy: 0.4531\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.2378 - accuracy: 0.4766\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0550 - accuracy: 0.6016\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.8867 - accuracy: 0.6719\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.8080 - accuracy: 0.6953\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.7241 - accuracy: 0.7578\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5456 - accuracy: 0.7891\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5502 - accuracy: 0.8047\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4235 - accuracy: 0.8281\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4116 - accuracy: 0.8672\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3779 - accuracy: 0.8672\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.2969 - accuracy: 0.9062\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.2346 - accuracy: 0.9453\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.2069 - accuracy: 0.9453\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1951 - accuracy: 0.9297\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1344 - accuracy: 0.9531\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1448 - accuracy: 0.9297\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1492 - accuracy: 0.9375\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.2553 - accuracy: 0.9062\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.2159 - accuracy: 0.9062\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3001 - accuracy: 0.8984\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4679 - accuracy: 0.8828\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1222 - accuracy: 0.9609\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.2116 - accuracy: 0.9219\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1338 - accuracy: 0.9609\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1334 - accuracy: 0.9609\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0902 - accuracy: 0.9609\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0614 - accuracy: 0.9844\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0622 - accuracy: 0.9844\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0206 - accuracy: 0.9922\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0044 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7881c17e0b20>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANKslj6irYyt",
        "outputId": "0f19ec5a-9bd7-46f8-d19a-a82aa1e108a1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 13ms/step - loss: 1.3637 - accuracy: 0.7679\n",
            "\n",
            "Test accuracy =  0.7678571343421936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows you to see the mislabelled examples\n",
        "C = 5\n",
        "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
        "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
        "pred = model.predict(X_test_indices)\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test_indices\n",
        "    num = np.argmax(pred[i])\n",
        "    if(num != Y_test[i]):\n",
        "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs4MJAdnrp3Z",
        "outputId": "2fb0fae8-80f1-4d8f-d6f6-dedcfd0a2f50"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 11ms/step\n",
            "Expected emoji:😄 prediction: he got a very nice raise❤️\n",
            "Expected emoji:😄 prediction: she got me a nice present❤️\n",
            "Expected emoji:😄 prediction: he is a good friend❤️\n",
            "Expected emoji:😄 prediction: We had such a lovely dinner tonight❤️\n",
            "Expected emoji:😞 prediction: work is hard😄\n",
            "Expected emoji:😞 prediction: This girl is messing with me❤️\n",
            "Expected emoji:🍴 prediction: any suggestions for dinner😄\n",
            "Expected emoji:😞 prediction: she is a bully❤️\n",
            "Expected emoji:😄 prediction: valentine day is near❤️\n",
            "Expected emoji:😄 prediction: will you be my valentine❤️\n",
            "Expected emoji:❤️ prediction: I like your jacket 😄\n",
            "Expected emoji:😄 prediction: What you did was awesome😞\n",
            "Expected emoji:🍴 prediction: I did not have breakfast 😞\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.\n",
        "x_test = np.array(['I cannot play'])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz9n9JJysFFL",
        "outputId": "e7e031c1-e782-4a7d-e71b-c27965afc574"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "I cannot play ⚾\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.array([\"Congratulations on finishing this assignment and building an Emojifier. \"])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EDwCaTMsOIy",
        "outputId": "bc7a36ef-30df-4e94-bbf4-5f2d333c56e6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Congratulations on finishing this assignment and building an Emojifier.  😄\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.array([\"You've completed this notebook, and harnessed the power of LSTMs   \"])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUlard3ssivD",
        "outputId": "05254a47-cd0f-4eba-8072-a22f12fda8c3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "You've completed this notebook, and harnessed the power of LSTMs    😞\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iDIk94Ou_J0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}